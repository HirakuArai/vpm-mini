apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: hello-ai-minimal
  namespace: monitoring
  labels:
    release: vpm-mini-kube-prometheus-stack
spec:
  groups:
  - name: hello-ai-availability
    interval: 30s
    rules:
    - alert: HelloAIServiceDown
      expr: up{job=~".*hello-ai.*"} == 0
      for: 2m
      labels:
        severity: critical
        service: hello-ai
      annotations:
        summary: "Hello AI service is down"
        description: "Hello AI metrics endpoint has been down for more than 2 minutes"
    
  - name: hello-ai-performance
    interval: 30s
    rules:
    - alert: HelloAIHighLatency
      expr: histogram_quantile(0.95, rate(http_request_duration_seconds_bucket{job=~".*hello-ai.*"}[5m])) > 0.5
      for: 5m
      labels:
        severity: warning
        service: hello-ai
      annotations:
        summary: "Hello AI high latency detected"
        description: "95th percentile latency is above 500ms for 5 minutes"
    
    - alert: HelloAIHighErrorRate
      expr: rate(http_requests_total{job=~".*hello-ai.*",status=~"5.."}[5m]) > 0.05
      for: 5m
      labels:
        severity: warning
        service: hello-ai
      annotations:
        summary: "Hello AI high error rate"
        description: "Error rate is above 5% for 5 minutes"
